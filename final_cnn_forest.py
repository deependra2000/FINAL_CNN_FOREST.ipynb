# -*- coding: utf-8 -*-
"""FINAL_CNN_FOREST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/141rQ5e0xEh0i1Fq_VSYtHOcu7sRh35Bl
"""

## Import neccessary packages
import os
import cv2
import random
import warnings
import argparse
import itertools
import numpy as np
from imutils import paths
import matplotlib.pyplot as plt
warnings.filterwarnings("ignore")
from tqdm import tqdm_notebook as tqdm

# import the tensorflow.keras packages
from tensorflow.keras.layers import Dense
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix , accuracy_score, classification_report

SEED = 50

from google.colab import drive
drive.mount('/content/drive')

# create CNN Model(Yann LeCun et al:1998)

class LeNet:
    @staticmethod
    def build(width, height, depth, classes):
        # initialize the model
        model = Sequential()                ## siamese networks
        inputShape = (height, width, depth)

        # if we are using "channels first", update the input shape
        print(K.image_data_format())
        if K.image_data_format() == "channels_first":
            inputShape = (depth, height, width)

        # first set of CONV => RELU => POOL layers
        model.add(Conv2D(20, (5, 5), padding="same",input_shape=inputShape))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

        # second set of CONV => RELU => POOL layers
        model.add(Conv2D(50, (5, 5), padding="same"))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

        # first (and only) set of FC => RELU layers
        model.add(Flatten())
        model.add(Dense(500))
        model.add(Activation("relu"))

        # softmax classifier
        model.add(Dense(classes))
        model.add(Activation("softmax"))

        # return the constructed network architecture
        return model

DATASET = "/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/CNN_Train"  # this folder must contain three subfolder with images
MODEL = "/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/Scene.model" # name to store the model on disk
PLOT = "plot.png" # plot name

list(paths.list_images(DATASET))[:5]

imagePaths = sorted(list(paths.list_images(DATASET)))
random.seed(SEED)
random.shuffle(imagePaths)
imagePaths[:5]

len(imagePaths)

imagePaths[5]

image1=cv2.imread(imagePaths[5])
image1

## This is the shape of one image
image=cv2.imread(imagePaths[5])
print("Shape of one image=>",image.shape)

##Resize it => deep learning models train faster on small images
image = cv2.resize(image, (28, 28))
print("Resize Shape of one image=>",image.shape)
print("Type",type(image))

##convert it to array
image = img_to_array(image)
print("Type",type(image))

from google.colab.patches import cv2_imshow
image=cv2.imread(imagePaths[5])
cv2_imshow(image)

image = cv2.resize(image,(100,100))
cv2_imshow(image)

imagePaths[5]

imagePaths[5].split("/")

imagePaths[5].split("/")[-2]

## Extract The Label From Image Path
label = imagePaths[5].split(os.path.sep)[-2]
label

# initialize the data and labels
print("[INFO] loading images...")
data = []
labels = []

# grab the image paths and randomly shuffle them
imagePaths = sorted(list(paths.list_images(DATASET)))
random.seed(SEED)
random.shuffle(imagePaths)

# progress bar
with tqdm(total=len(imagePaths)) as pbar:
    # loop over the input images
    for idx, imagePath in enumerate(imagePaths):
        # load the image, pre-process it, and store it in the data list
        image = cv2.imread(imagePath)
        image = cv2.resize(image, (28, 28))
        image = img_to_array(image)
        data.append(image)
        # extract the class label from the image path and update the
        # labels list
        label = imagePath.split(os.path.sep)[-2]

        if label == "Buildings":
            label = 0
        elif label == "Forest":
            label = 1
        elif label == "Sea":
            label = 2

        # print("pr: ", label)

        labels.append(label)

        # update the progressbar
        pbar.update(1)

#pixel values are integers that range from 0 (black) to 255 (white).
data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)

data.shape

data[1][27]

labels

(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=SEED)

trainX.shape

trainY.shape

trainY[1]

trainY[2]

trainY[4]

trainY = to_categorical(trainY, num_classes=3)
testY = to_categorical(testY, num_classes=3)

trainY[1]

trainY[2]

trainY[4]

"""# Data Preprocessing (Augumentation)"""

# construct the image generator for data augmentation
aug = ImageDataGenerator(rotation_range=30,
                         width_shift_range=0.1,
                         height_shift_range=0.1,
                         shear_range=0.2,
                         zoom_range=0.2,
                         horizontal_flip=True,
                         fill_mode="nearest")

EPOCHS = 200
INIT_LR = 1e-3
BS = 32

# initialize the model
print("[INFO] compiling model...")
model = LeNet.build(width=28, height=28, depth=3, classes=3)
opt = Adam(learning_rate=INIT_LR)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
print("[INFO] model complied...")

print(model.summary())



# train the network
print("[INFO] training network...")
H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),
              validation_data=(testX, testY),
              steps_per_epoch=len(trainX) // BS,
              epochs=EPOCHS,
              verbose=1)

# plot the training and validation accuracy
N = np.arange(0, EPOCHS)
plt.style.use("ggplot")
plt.figure(figsize = [10,8])
plt.plot(N, H.history["accuracy"], label="train_acc")
plt.plot(N, H.history["val_accuracy"], label="val_acc")
plt.title("CNN: Training and Validation Accuracy")
plt.xlabel("Epoch #", weight="bold")
plt.ylabel("Accuracy", weight="bold")
plt.legend()
plt.show()

# plot the training and validation loss
N = np.arange(0, EPOCHS)
plt.style.use("ggplot")
plt.figure(figsize = [10,8])
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.title("CNN: Training & Validation Loss")
plt.xlabel("Epoch #", weight="bold")
plt.ylabel("Loss", weight="bold")
plt.legend()
plt.show()

model.save("/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/Scene_New.model")

# Commented out IPython magic to ensure Python compatibility.
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import numpy as np
import argparse
import imutils
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

def display_img(img):
    fig = plt.figure(figsize=(12,10))
    plt.grid()
    ax = fig.add_subplot(111)
    ax.imshow(img)

from tensorflow.keras.models import load_model
import pickle
import cv2

testImagePaths = sorted(list(paths.list_images('/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/CNN_test_examples')))   # data folder with 2 categorical folders
imagePath = testImagePaths[0]
print(imagePath)
image = cv2.imread(imagePath)
print(image.shape)
image = cv2.resize(image, (28, 28))
print(image.shape)
print(image[0][0])
image = image.astype("float") / 255.0
print(image[0][0])
image = img_to_array(image)
image = np.expand_dims(image, axis=0)

model = load_model("/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/Scene_New.model")

prd_conf = model.predict(image)[0]
prd_conf

np.argmax(prd_conf)

all_class = ["Buildings", "Forest", "Sea"]
label = all_class[np.argmax(prd_conf)]
label

# import the necessary packages
from tensorflow.keras.models import load_model
import pickle
import cv2

# # load the model
print("[INFO] loading network and...")
#model = load_model(MODEL)
model = load_model("/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/Scene_New.model")
# grab the image paths and randomly shuffle themt
testImagePaths = sorted(list(paths.list_images('/content/drive/MyDrive/Data Science/Deep Learning/CNN/Dataset/CNN_test_examples')))   # data folder with 2 categorical folders

all_class = ["Buildings", "Forest", "Sea"]


# progress bar
with tqdm(total=len(testImagePaths)) as pbar:

    for imagePath in testImagePaths:

        # load the image
        image = cv2.imread(imagePath)
        orig = image.copy()

        # pre-process the image for classification
        image = cv2.resize(image, (28, 28))
        image = image.astype("float") / 255.0
        image = img_to_array(image)
        image = np.expand_dims(image, axis=0)

        # classify the input image
        prd_conf = model.predict(image)[0]

        # build the label
        label = all_class[np.argmax(prd_conf)]
        proba = prd_conf[np.argmax(prd_conf)]

        label = "{}: {:.2f}%".format(label, proba * 100)

        # draw the label on the image
        output = imutils.resize(orig, width=400)
        cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,
            0.7, (255, 0, 0), 2)

        # convert img to rgb format and display in notebook
        img = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)
        display_img(img)

        pbar.update(1)

pip install gradio

import gradio as gr

def predict_image(image):
    # load the image

    # pre-process the image for classification
    image = cv2.resize(image, (28, 28))
    image = image.astype("float") / 255.0
    image = img_to_array(image)
    image = np.expand_dims(image, axis=0)


    preds = model.predict(image)[0]
    result = dict()
    result["Buildings"] = round(float(list(preds)[0]), 3)
    result["Forest"] = round(float(list(preds)[1]), 3)
    result["Sea"] = round(float(list(preds)[2]), 3)

    print(result)

    return result

im = gr.inputs.Image(shape=(32,32))
label = gr.outputs.Label(num_top_classes=3)

gr.Interface(fn=predict_image, inputs=im, outputs=label, capture_session=True, title="CNN Demo").launch(share=True)

import tensorflow as tf
print(tf.__version__)